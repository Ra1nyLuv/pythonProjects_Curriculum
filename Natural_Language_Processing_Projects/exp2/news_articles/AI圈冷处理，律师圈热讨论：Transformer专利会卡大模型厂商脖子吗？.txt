标题: AI圈冷处理，律师圈热讨论：Transformer专利会卡大模型厂商脖子吗？
链接: https://www.163.com/tech/article/JSPQEO6H00098IEO.html

正文:
一场关于Transformer专利的讨论，正在两个世界里以截然不同的方式展开。
对他们而言，Transformer是一种常识级的存在，几乎像空气一样不言自明。他们认为：Transformer不仅是一项技术，更是一个生态。大家都在用，也早已与最初的模样不同，谷歌根本不可能动真格发动专利战。
他们更关注OpenAI是否在换架构，关心KV缓存如何优化、怎么压缩信息，怎么快速收敛，或者下一个prompt tuning能不能提速5%。
当前部分使用Transformer架构的大模型,DeepSeek整理，网易科技制图
但在另一个空间——律师圈，气氛却截然不同。
知名律所的专利律师正在朋友圈和会议室中频繁提及“注意力机制”“代理授权”“中国驳回”这些关键词。
有人在推演一旦专利通过后，哪些大模型公司会被波及；有人开始查阅中、美、欧专利数据库，一页页比对谷歌的申请文本；还有律师干脆直接到大模型公司登门拜访，告诉他们是时候注意到这件事情了。
一位律师感慨：“你们搞AI的啊，真是太乐观了。谷歌要是真开始收专利费，你们才知道什么叫全球化风险。”
于是，一个“毫无反应”的技术世界和一个“高度活跃”的法律世界，在谷歌Transformer专利复审这件事上，对着同一件事，双方没有对话，做出完全不同的判断。
但也正是这种割裂，在提醒着我们：AI 的竞争绝不只是数据、算力与算法的竞速，更是关于规则制定、权利边界与商业博弈的复合战争。
在 AI 圈，Transformer 是常识，是已经嵌入无数大模型底层结构的“地基”。它由谷歌研究团队于2017年，在论文《Attention Is All You Need》中提出，目前已成为大语言模型（如 GPT、BERT、Llama）的基石。
截至2025年3月，《Attention Is All You Need》论文已被引用超17万次，是 AI 领域最具影响力的研究之一。
该论文引入了自注意力机制和多头注意力机制，注意力机制让模型能在处理语言序列时，自主判断哪些词更重要，从而显著提高了效率与表达能力。谷歌围绕这一机制，已在全球布局了数十项同族专利，并在美国、欧洲、日本等地陆续获批。
谷歌Transformer发明专利全球布局概况
但在国内律师圈，它却仍是一个悬而未决的法律议题。
值得注意的是，谷歌Transformer发明专利并非针对整个Transformer架构，而是针对其核心底层机制，也就是我们通常所讲的“注意力机制”。
2024年1月，中国国家知识产权局以“不属于专利法规定的技术方案”为由，驳回了谷歌的专利申请。
驳回决定指出，该专利主要涉及对神经网络算法的改进，未能解决具体技术领域的具体技术问题，未能采用专利法意义上的技术手段，也未能实现专利法意义上的技术效果。
听上去术语复杂，其实问题出在两个核心点：一是这项发明只是对神经网络算法的改进，并未解决某个具体的工程或技术问题；二是注意力机制是算法内部的计算逻辑，不属于被中国专利法承认的“技术手段”。
随后，谷歌主动调整。2024年4月，谷歌将专利限缩到“摘要”和“问答”两个应用场景，并向中国国家知识产权局提交复审请求。同年11月14日，国家知识产权局撤销此前驳回决定，专利进入实质性审查。
换句话说，谷歌不再主张整个注意力机制都属于自己，而是希望先在部分高频应用上取得突破。
这也意味着，一旦大模型在“摘要”和“问答”两个应用场景中应用“注意力机制”，就很难逃脱谷歌的专利保护范围。
图注：谷歌Transformer中国发明专利的最新修改文本
2024年12月31日，中国国家知识产权局下发第四次审查意见通知书，指出说明书公开不充分。截至本文撰稿时，谷歌对此还没有答复。
图注：《国家知识产权局的第四次审查意见通知书》
但北京高文律所合伙人、专利律师王冬告诉网易科技，无论删除权利要求还是据理力争，说明书公开不充分的问题不难克服。也就是说，这件中国专利未来授权概率很高。
如果这些同族专利最终获得授权，将有助于谷歌在 AI 时代构建全球技术壁垒，让Transformer变成企业必须“付费通行”的高速公路。
一旦谷歌主张专利侵权，企业或陷入“三选一”困局
一旦专利获得授权，问题就不再是“能不能用”，而可能是“怎么用”。
发明专利是专利体系中保护力度最强的，最长可达20年。此次我们所讨论的谷歌 Transformer 架构的专利，就属于发明专利范畴。
获得专利授权后，持有者可以通过许可、转让或诉讼实现商业收益，并对侵权者要求停止侵害，并赔偿损失。
当然，专利侵权的确认和范畴还需要复杂的界定。但一旦确认侵权，依赖该架构的企业，则或将面临三种选择：
对于巨头公司来说，支付授权费或许只是成本问题。但对技术路径已经依赖Transformer架构、资金资源有限的中小企业而言，这几乎等于一纸封路令。
更隐秘的风险在于：如果谷歌的专利保护范围足够宽泛，即使后来者对架构进行了优化和改良，也依然可能落入其权利要求的“覆盖区”，仍然构成侵权。这让谷歌专利更像是一条收费高速路，所有人都得“买票通行”。
行业人士向网易科技表示，专利更多时候是一个防守型武器。它真正的价值，在于确立优先权——当有人对你发起专利诉讼，你可以用自家的专利组合进行反制。这也是为什么科技巨头普遍选择通过交叉授权来达成一种“核威慑”式的平衡。
谷歌过去在 AI 领域的专利布局，也更像是在修一座“技术护城河”。它要的是位置，是议价权，而不是立即变现的通行费。
这背后还有现实考量：专利诉讼周期长、成本高、结果不确定。比如甲骨文诉谷歌的 Java 侵权案，整整打了十年，最后谷歌虽然赢了，但双方都付出了巨额代价。
涉谷歌的部分专利纠纷案件及结果，DeepSeek整理，网易科技制图
更关键的是，如果谷歌今天挥舞专利大棒，明天就可能面对整个行业的联合反弹。甚至可能遭遇反垄断调查，或被贴上“扼杀创新”的标签，动摇它在开发者社区中的信誉。
综上，谷歌主动对AI大模型公司发起专利诉讼的可能性极低。但这并不意味着它不会发生。
王冬律师指出，这就像达摩克里斯之剑——它或许不会立刻落下，但谁也无法忽视它的存在。例如，谷歌可以将Transformer专利许可或转让给第三方专利运营公司，从而发起对大模型公司的狙击。这在通信行业早有前车之鉴。
Transformer并非唯一，大模型架构探索仍在继续
尽管谷歌专利引发了行业高度关注，但从技术演进的角度看，Transformer 可能并非不可替代的唯一选项。
元始智能联合创始人、COO罗璇向网易科技透露，虽然Transformer 仍是当前主流架构，但行业内已有迹象表明，头部 AI 公司和研究机构已经正在探索“非 Transformer ”架构的替代方案。
罗璇表示，这不仅仅是一个国产化替代的问题，更是企业在面对 Transformer 架构能力瓶颈、算力资源紧张背景下，为追求更高效率和更强性能所做的主动技术突围。
腾讯混元 T1就引入了 Hybrid-Mamba-Transformer 融合架构，通过结构调整大幅降低计算复杂度，并优化 KV-Cache 的内存占用，提升推理和训练效率。
英伟达也在其开源大模型 Nemotron-H 中使用了类似的混合架构，推理速度达到同体量竞品的三倍，显著提高了在实际部署中的能效比。
而在部署层面，微软则更进一步：已在 Windows 系统中默认内置 RWKV 模型调用库。罗璇告诉网易科技，RWKV 作为一种非 Transformer 架构，已经成为当前部署最广泛的非transformer架构。
部分非Transformer架构的模型，DeepSeek整理，网易科技制图
在这些架构探索和专利博弈的背后，反映出的其实是一个更深层的行业逻辑：
AI 竞争的战场，从来不仅是技术优劣的单点比拼，更是围绕技术生态和制度规则的全局较量。
谁拥有更高的效率、更强的通用性，当然能在模型性能上占据先机；但谁掌握标准、协议的制定权，才能在全球范围内确立自己的主导地位。
对国内 AI 企业而言，大模型不仅仅是技术课题，更是建立商业护城河、构建国际竞争力的核心资产。
开放与封闭、共享与垄断、创新与合规——企业要想穿越下一阶段的全球博弈，就必须不仅擅长写代码，也要擅长读懂“游戏规则”。
谷歌的 Transformer 专利最终是否会成为 AI 产业的“紧箍咒”，尚未可知。但可以肯定的是：未来 AI 的竞争，早已不止是架构之争，也不止是参数规模的军备竞赛。
智东西 2025-04-14 19:28:22
科技新知 2025-04-14 15:57:21
钛媒体APP 2025-04-15 09:48:10
新闻早点到 2025-04-14 17:42:10
IPRdaily 2025-04-15 10:08:54
虹婷爱搞笑 2025-04-11 17:06:31
幽默发电厂 2025-04-13 16:07:10
大王爆笑社 2025-04-14 10:11:18
澎湃新闻 2025-04-15 10:06:46
机器之心Pro 2025-01-15 15:44:46
齐鲁壹点 2025-04-15 13:01:16
大象新闻 2025-04-15 15:02:02
量子位 2025-04-15 09:57:15
量子位 2025-03-03 09:57:09
中关村丰台园 2025-04-14 19:05:26
财联社 2025-04-15 14:57:10
搞笑柒月 2025-04-14 13:27:37
量子位 2025-04-01 11:01:46
量子位 2025-03-29 17:36:24
量子位 2025-04-09 10:10:32
量子位 2025-01-26 12:43:42
ConfusionMax 2025-04-15 06:17:24
量子位 2025-01-21 18:07:40
量子位 2025-02-15 12:09:37
南北分界线 2025-04-14 22:06:31
量子位 2025-01-10 16:29:56
量子位 2025-04-14 15:31:01
火炼树 2025-04-14 22:11:58
中国经营报 2025-04-15 04:07:18
量子位 2025-04-15 11:59:12
万大叔来了 2025-04-12 16:47:25
财联社 2025-02-25 23:59:43
量子位 2025-01-22 18:06:18
量子位 2025-04-02 21:22:14
量子位 2025-02-18 20:48:36
量子位 2025-01-22 11:13:04
量子位 2025-03-07 14:20:34
火炼树 2025-04-15 12:54:25
量子位 2025-04-11 09:06:11
量子位 2025-03-04 20:07:47